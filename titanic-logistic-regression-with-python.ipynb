{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c833cbf5-74db-44ff-90fa-b600ff0a09d7","_uuid":"39dbc095f99dcec6d25a7a4561e81bb641078622"},"source":["<a id=\"t4.\"></a>\n","# 4. Logistic Regression and Results"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b70cda8a-e8d9-44a6-b9f0-2b365fdf3428","_uuid":"136cf9e02ea1ab48a397f534b491fb2d9dbb5684"},"source":["<a id=\"t4.1.\"></a>\n","## 4.1. Feature selection\n","\n","<a id=\"t4.1.1.\"></a>\n","### 4.1.1. Recursive feature elimination\n","\n","Given an external estimator that assigns weights to features, recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a `coef_ attribute` or through a `feature_importances_` attribute. Then, the least important features are pruned from current set of features.That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n","\n","References: <br>\n","http://scikit-learn.org/stable/modules/feature_selection.html <br>"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"11a2a468-20df-40cd-a4ba-4ae7bd2fc403","_uuid":"64befdf1182c2b4e845f488f5bfd0e19ce3dc17a","trusted":true},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_selection import RFE\n","\n","cols = [\"Age\",\"Fare\",\"TravelAlone\",\"Pclass_1\",\"Pclass_2\",\"Embarked_C\",\"Embarked_S\",\"Sex_male\",\"IsMinor\"] \n","X = final_train[cols]\n","y = final_train['Survived']\n","# Build a logreg and compute the feature importances\n","model = LogisticRegression()\n","# create the RFE model and select 8 attributes\n","rfe = RFE(model, 8)\n","rfe = rfe.fit(X, y)\n","# summarize the selection of the attributes\n","print('Selected features: %s' % list(X.columns[rfe.support_]))"]},{"cell_type":"markdown","metadata":{"_cell_guid":"29281bd5-b954-4f3d-87e3-7416b1ec8c6b","_uuid":"626da3348b48ced3564e6e05bdb0c3b4bd1402e6"},"source":["<a id=\"t4.1.2.\"></a>\n","### 4.1.2. Feature ranking with recursive feature elimination and cross-validation\n","\n","RFECV performs RFE in a cross-validation loop to find the optimal number or the best number of features. Hereafter a recursive feature elimination applied on logistic regression with automatic tuning of the number of features selected with cross-validation."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7239aa6f-7fd2-4b75-a387-f6624f1c338c","_uuid":"53d79f38cfe33d75d6ff869a443b9a29c93b4cbd","trusted":true},"outputs":[],"source":["from sklearn.feature_selection import RFECV\n","# Create the RFE object and compute a cross-validated score.\n","# The \"accuracy\" scoring is proportional to the number of correct classifications\n","rfecv = RFECV(estimator=LogisticRegression(), step=1, cv=10, scoring='accuracy')\n","rfecv.fit(X, y)\n","\n","print(\"Optimal number of features: %d\" % rfecv.n_features_)\n","print('Selected features: %s' % list(X.columns[rfecv.support_]))\n","\n","# Plot number of features VS. cross-validation scores\n","plt.figure(figsize=(10,6))\n","plt.xlabel(\"Number of features selected\")\n","plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n","plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b1b3b56f-2f5f-47d6-9375-62c11e49ce79","_uuid":"e9d52d5b182c0a01218982e844e53d5278e0d98a"},"source":["As we see, eight variables were kept. "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08986ec4-79ff-466b-b763-61bf84a0879b","_uuid":"3f6950a7c24c629b72e17e54c556f3c183b3f779","trusted":true},"outputs":[],"source":["Selected_features = ['Age', 'TravelAlone', 'Pclass_1', 'Pclass_2', 'Embarked_C', \n","                     'Embarked_S', 'Sex_male', 'IsMinor']\n","X = final_train[Selected_features]\n","\n","plt.subplots(figsize=(8, 5))\n","sns.heatmap(X.corr(), annot=True, cmap=\"RdYlGn\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"a7455afe-9716-4189-b207-f1cc9facce12","_uuid":"46b76691c5f109b17f805f233a5ad5ba900b353b"},"source":["<a id=\"t4.2.\"></a>\n","## 4.2. Review of model evaluation procedures\n","\n","Motivation: Need a way to choose between machine learning models\n","* Goal is to estimate likely performance of a model on out-of-sample data\n","\n","Initial idea: Train and test on the same data\n","* But, maximizing training accuracy rewards overly complex models which overfit the training data\n","\n","Alternative idea: Train/test split\n","* Split the dataset into two pieces, so that the model can be trained and tested on different data\n","* Testing accuracy is a better estimate than training accuracy of out-of-sample performance\n","* Problem with train/test split\n","    * It provides a high variance estimate since changing which observations happen to be in the testing set can significantly change testing accuracy\n","    * Testing accuracy can change a lot depending on a which observation happen to be in the testing set\n","\n","Reference: <br>\n","http://www.ritchieng.com/machine-learning-cross-validation/ <br>"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b894002e-07cf-4d02-b708-a2ac387eed54","_uuid":"e35125f8aa230d4875541aa4f6b5964d2f14a6a3"},"source":["<a id=\"t4.2.1.\"></a>\n","### 4.2.1. Model evaluation based on simple train/test split using `train_test_split()` function"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84233f59-f3c7-4ea0-884d-96f8ad4d5b10","_uuid":"46336228eeb864bc82e6739768122579d1c9634c","trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \n","from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\n","\n","# create X (features) and y (response)\n","X = final_train[Selected_features]\n","y = final_train['Survived']\n","\n","# use train/test split with different random_state values\n","# we can change the random_state values that changes the accuracy scores\n","# the scores change a lot, this is why testing scores is a high-variance estimate\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n","\n","# check classification scores of logistic regression\n","logreg = LogisticRegression()\n","logreg.fit(X_train, y_train)\n","y_pred = logreg.predict(X_test)\n","y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n","[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\n","print('Train/Test split results:')\n","print(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\n","print(logreg.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))\n","print(logreg.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))\n","\n","idx = np.min(np.where(tpr > 0.95)) # index of the first threshold for which the sensibility > 0.95\n","\n","plt.figure()\n","plt.plot(fpr, tpr, color='coral', label='ROC curve (area = %0.3f)' % auc(fpr, tpr))\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.plot([0,fpr[idx]], [tpr[idx],tpr[idx]], 'k--', color='blue')\n","plt.plot([fpr[idx],fpr[idx]], [0,tpr[idx]], 'k--', color='blue')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\n","plt.ylabel('True Positive Rate (recall)', fontsize=14)\n","plt.title('Receiver operating characteristic (ROC) curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","print(\"Using a threshold of %.3f \" % thr[idx] + \"guarantees a sensitivity of %.3f \" % tpr[idx] +  \n","      \"and a specificity of %.3f\" % (1-fpr[idx]) + \n","      \", i.e. a false positive rate of %.2f%%.\" % (np.array(fpr[idx])*100))"]},{"cell_type":"markdown","metadata":{"_cell_guid":"6292c3f2-6be9-45e4-be33-1dca41e604a7","_uuid":"ba0017b461cea0b8849746e76475598bbba7c9ce"},"source":["<a id=\"t4.2.2.\"></a>\n","### 4.2.2. Model evaluation based on K-fold cross-validation using `cross_val_score()` function "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32a611ae-b2b7-43e0-8fa8-3cc56e351bf6","_uuid":"7f0aba7b861c3fa1748060b4733778851fb00a31","trusted":true},"outputs":[],"source":["# 10-fold cross-validation logistic regression\n","logreg = LogisticRegression()\n","# Use cross_val_score function\n","# We are passing the entirety of X and y, not X_train or y_train, it takes care of splitting the data\n","# cv=10 for 10 folds\n","# scoring = {'accuracy', 'neg_log_loss', 'roc_auc'} for evaluation metric - althought they are many\n","scores_accuracy = cross_val_score(logreg, X, y, cv=10, scoring='accuracy')\n","scores_log_loss = cross_val_score(logreg, X, y, cv=10, scoring='neg_log_loss')\n","scores_auc = cross_val_score(logreg, X, y, cv=10, scoring='roc_auc')\n","print('K-fold cross-validation results:')\n","print(logreg.__class__.__name__+\" average accuracy is %2.3f\" % scores_accuracy.mean())\n","print(logreg.__class__.__name__+\" average log_loss is %2.3f\" % -scores_log_loss.mean())\n","print(logreg.__class__.__name__+\" average auc is %2.3f\" % scores_auc.mean())"]},{"cell_type":"markdown","metadata":{"_cell_guid":"bf358561-2762-4b24-b33b-bfda3c5d725f","_uuid":"9debd9d4281cf7893159aa2cb1f7993652d60228"},"source":["<a id=\"t4.2.3.\"></a>\n","### 4.2.3. Model evaluation based on K-fold cross-validation using `cross_validate()` function "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9ea95aac-00b2-413e-ab86-c6b8782c40ef","_uuid":"90840c89d42e9284c9480a256dc259778c3a5b1b","trusted":true},"outputs":[],"source":["from sklearn.model_selection import cross_validate\n","\n","scoring = {'accuracy': 'accuracy', 'log_loss': 'neg_log_loss', 'auc': 'roc_auc'}\n","\n","modelCV = LogisticRegression()\n","\n","results = cross_validate(modelCV, X, y, cv=10, scoring=list(scoring.values()), \n","                         return_train_score=False)\n","\n","print('K-fold cross-validation results:')\n","for sc in range(len(scoring)):\n","    print(modelCV.__class__.__name__+\" average %s: %.3f (+/-%.3f)\" % (list(scoring.keys())[sc], -results['test_%s' % list(scoring.values())[sc]].mean()\n","                               if list(scoring.values())[sc]=='neg_log_loss' \n","                               else results['test_%s' % list(scoring.values())[sc]].mean(), \n","                               results['test_%s' % list(scoring.values())[sc]].std()))"]},{"cell_type":"markdown","metadata":{"_cell_guid":"96fc0718-8678-44b5-ba1f-9155303a4ffe","_uuid":"c29fd32bbe1fb2740587524d8ddbf08d85832d9c"},"source":["<font color=bleu>What happens when we add the feature \"Fare\"?<font>"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"80b5d5c3-ead3-48f7-84eb-42c801e0370a","_uuid":"0fdf4a257a49b0b47552a4ed307c86852c4ed271","trusted":true},"outputs":[],"source":["cols = [\"Age\",\"Fare\",\"TravelAlone\",\"Pclass_1\",\"Pclass_2\",\"Embarked_C\",\"Embarked_S\",\"Sex_male\",\"IsMinor\"]\n","X = final_train[cols]\n","\n","scoring = {'accuracy': 'accuracy', 'log_loss': 'neg_log_loss', 'auc': 'roc_auc'}\n","\n","modelCV = LogisticRegression()\n","\n","results = cross_validate(modelCV, final_train[cols], y, cv=10, scoring=list(scoring.values()), \n","                         return_train_score=False)\n","\n","print('K-fold cross-validation results:')\n","for sc in range(len(scoring)):\n","    print(modelCV.__class__.__name__+\" average %s: %.3f (+/-%.3f)\" % (list(scoring.keys())[sc], -results['test_%s' % list(scoring.values())[sc]].mean()\n","                               if list(scoring.values())[sc]=='neg_log_loss' \n","                               else results['test_%s' % list(scoring.values())[sc]].mean(), \n","                               results['test_%s' % list(scoring.values())[sc]].std()))"]},{"cell_type":"markdown","metadata":{"_cell_guid":"e6d3b029-550e-4142-8d9a-c9670b8cd529","_uuid":"99b2a4c72f6c50fd11abda7a6463aca5154cacd7"},"source":["<font color=red>We notice that the model is slightly deteriorated. The \"Fare\" variable does not carry any useful information. Its presence is just a noise for the logistic regression model.<font>"]},{"cell_type":"markdown","metadata":{"_cell_guid":"f485ca4c-2172-4383-979e-21e78a66192c","_uuid":"ec44fbaddbc23f03a8ac470391f41ce35f40cf72"},"source":["<a id=\"t4.3.\"></a>\n","## 4.3. GridSearchCV evaluating using multiple scorers simultaneously"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a39cb49-b446-4ffa-88a2-e37b627eb5e5","_uuid":"765695a9712d3fe1ecff10f17dcc077a80ed7682","trusted":true},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","X = final_train[Selected_features]\n","\n","param_grid = {'C': np.arange(1e-05, 3, 0.1)}\n","scoring = {'Accuracy': 'accuracy', 'AUC': 'roc_auc', 'Log_loss': 'neg_log_loss'}\n","\n","gs = GridSearchCV(LogisticRegression(), return_train_score=True,\n","                  param_grid=param_grid, scoring=scoring, cv=10, refit='Accuracy')\n","\n","gs.fit(X, y)\n","results = gs.cv_results_\n","\n","print('='*20)\n","print(\"best params: \" + str(gs.best_estimator_))\n","print(\"best params: \" + str(gs.best_params_))\n","print('best score:', gs.best_score_)\n","print('='*20)\n","\n","plt.figure(figsize=(10, 10))\n","plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",fontsize=16)\n","\n","plt.xlabel(\"Inverse of regularization strength: C\")\n","plt.ylabel(\"Score\")\n","plt.grid()\n","\n","ax = plt.axes()\n","ax.set_xlim(0, param_grid['C'].max()) \n","ax.set_ylim(0.35, 0.95)\n","\n","# Get the regular numpy array from the MaskedArray\n","X_axis = np.array(results['param_C'].data, dtype=float)\n","\n","for scorer, color in zip(list(scoring.keys()), ['g', 'k', 'b']): \n","    for sample, style in (('train', '--'), ('test', '-')):\n","        sample_score_mean = -results['mean_%s_%s' % (sample, scorer)] if scoring[scorer]=='neg_log_loss' else results['mean_%s_%s' % (sample, scorer)]\n","        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n","        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n","                        sample_score_mean + sample_score_std,\n","                        alpha=0.1 if sample == 'test' else 0, color=color)\n","        ax.plot(X_axis, sample_score_mean, style, color=color,\n","                alpha=1 if sample == 'test' else 0.7,\n","                label=\"%s (%s)\" % (scorer, sample))\n","\n","    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n","    best_score = -results['mean_test_%s' % scorer][best_index] if scoring[scorer]=='neg_log_loss' else results['mean_test_%s' % scorer][best_index]\n","        \n","    # Plot a dotted vertical line at the best score for that scorer marked by x\n","    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n","            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n","\n","    # Annotate the best score for that scorer\n","    ax.annotate(\"%0.2f\" % best_score,\n","                (X_axis[best_index], best_score + 0.005))\n","\n","plt.legend(loc=\"best\")\n","plt.grid('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"4c32848c-e879-4ff0-9da4-7c572e80369e","_uuid":"d5e88e25cf05dc5c2ad7dcb574a91115c186047e"},"source":["<a id=\"t4.4.\"></a>\n","## 4.4. GridSearchCV evaluating using multiple scorers, RepeatedStratifiedKFold and pipeline for preprocessing simultaneously\n","\n","We can applied many tasks together for more in-depth evaluation like gridsearch using cross-validation based on k-folds repeated many times, that can be scaled or no with respect to many scorers and tunning on parameter for a given estimator!  "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a777c645-7413-4e1d-855a-0b416be1b48e","_uuid":"514d0e3aabe57aaad38d10d6101dbdac5af89ca4","trusted":true},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.pipeline import Pipeline\n","\n","#Define simple model\n","###############################################################################\n","C = np.arange(1e-05, 5.5, 0.1)\n","scoring = {'Accuracy': 'accuracy', 'AUC': 'roc_auc', 'Log_loss': 'neg_log_loss'}\n","log_reg = LogisticRegression()\n","\n","#Simple pre-processing estimators\n","###############################################################################\n","std_scale = StandardScaler(with_mean=False, with_std=False)\n","#std_scale = StandardScaler()\n","\n","#Defining the CV method: Using the Repeated Stratified K Fold\n","###############################################################################\n","\n","n_folds=5\n","n_repeats=5\n","\n","rskfold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=n_repeats, random_state=2)\n","\n","#Creating simple pipeline and defining the gridsearch\n","###############################################################################\n","\n","log_clf_pipe = Pipeline(steps=[('scale',std_scale), ('clf',log_reg)])\n","\n","log_clf = GridSearchCV(estimator=log_clf_pipe, cv=rskfold,\n","              scoring=scoring, return_train_score=True,\n","              param_grid=dict(clf__C=C), refit='Accuracy')\n","\n","log_clf.fit(X, y)\n","results = log_clf.cv_results_\n","\n","print('='*20)\n","print(\"best params: \" + str(log_clf.best_estimator_))\n","print(\"best params: \" + str(log_clf.best_params_))\n","print('best score:', log_clf.best_score_)\n","print('='*20)\n","\n","plt.figure(figsize=(10, 10))\n","plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",fontsize=16)\n","\n","plt.xlabel(\"Inverse of regularization strength: C\")\n","plt.ylabel(\"Score\")\n","plt.grid()\n","\n","ax = plt.axes()\n","ax.set_xlim(0, C.max()) \n","ax.set_ylim(0.35, 0.95)\n","\n","# Get the regular numpy array from the MaskedArray\n","X_axis = np.array(results['param_clf__C'].data, dtype=float)\n","\n","for scorer, color in zip(list(scoring.keys()), ['g', 'k', 'b']): \n","    for sample, style in (('train', '--'), ('test', '-')):\n","        sample_score_mean = -results['mean_%s_%s' % (sample, scorer)] if scoring[scorer]=='neg_log_loss' else results['mean_%s_%s' % (sample, scorer)]\n","        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n","        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n","                        sample_score_mean + sample_score_std,\n","                        alpha=0.1 if sample == 'test' else 0, color=color)\n","        ax.plot(X_axis, sample_score_mean, style, color=color,\n","                alpha=1 if sample == 'test' else 0.7,\n","                label=\"%s (%s)\" % (scorer, sample))\n","\n","    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n","    best_score = -results['mean_test_%s' % scorer][best_index] if scoring[scorer]=='neg_log_loss' else results['mean_test_%s' % scorer][best_index]\n","        \n","    # Plot a dotted vertical line at the best score for that scorer marked by x\n","    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n","            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n","\n","    # Annotate the best score for that scorer\n","    ax.annotate(\"%0.2f\" % best_score,\n","                (X_axis[best_index], best_score + 0.005))\n","\n","plt.legend(loc=\"best\")\n","plt.grid('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e52c3bfb-4325-4c27-9f8e-5514dae799c2","_uuid":"b3d12ca129d816d2434e74ed6574f829f826c3fc","trusted":true},"outputs":[],"source":["final_test['Survived'] = log_clf.predict(final_test[Selected_features])\n","final_test['PassengerId'] = test_df['PassengerId']\n","\n","submission = final_test[['PassengerId','Survived']]\n","\n","submission.to_csv(\"submission.csv\", index=False)\n","\n","submission.tail()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}
